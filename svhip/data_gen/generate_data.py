''' The preparation pipeline for trainingssets now packaged up in one 
module'''

import os
import sys

import_path = os.path.abspath(os.path.join(os.path.dirname(os.path.abspath(__file__)), os.pardir))
sys.path.append(import_path)
this_directory = os.path.dirname(os.path.realpath(__file__))

if 'alignment_handler/' not in sys.path:
    sys.path.append(os.path.join(this_directory, 'alignment_handler/'))
if 'help/' not in sys.path:
    sys.path.append(os.path.join(this_directory, 'help/'))
if 'parser/' not in sys.path:
    sys.path.append(os.path.join(this_directory, 'parser/'))

from window_handle import window_handle
from alignment_handle import Alignment_handle
from structural_conservation_filter import k_value_filter

if 'defaults/' not in sys.path:
    sys.path.append(os.path.abspath(os.path.join(import_path, 'defaults/')))
if 'scaling/python' not in sys.path:
    sys.path.append(os.path.abspath(os.path.join(import_path, 'scaling/python/')))
if 'currysoup/' not in sys.path:
    sys.path.append(os.path.abspath(os.path.join(import_path, 'currysoup/')))
#if 'logger/' not in sys.path:
#    sys.path.append(os.path.abspath(os.path.join(import_path, 'logger/')))
if 'statistics/' not in sys.path:
    sys.path.append(os.path.abspath(os.path.join(import_path, 'statistics/')))

import default_params
from currysoup import creation_soup
#import logger
from plotter import *
#from cleanup import clean_dir
#from time_clock import timer
import numpy as np
from pandas import DataFrame
from pandas import Series

#########################Default parameters#############################
"""
These are default parameters, for options not set manually on main() call.
Feel free to change as needed in defaults/default_params.py.

default_category = '1'
default_minident = 50
default_maxident = 98
default_simulateAlignment = False
default_sampleSize = 100
default_simulateSampleSize = 1
default_num_processes = multiprocessing.cpu_count()
default_mute = False
"""
defaults = default_params.get_testset_cr_defaults()


############################Core function###############################
"""
The hub through which all above functions are called. Core function is 
called by main() once input cmd line is parsed. For options please see
section 'main function call' below.
"""

def create_training_set(filename, param, outfilename, gen_neg = 0, function_log = None):
    
    """
    Unpack function parameters - recent changes have made this somewhat messy. 
    Will be redone in final version, but as more function/cmd line parameters 
    are to be added, this makes little sense now.
    """
    minid, maxid, k, window_size, n_proc, mute, step = param[1], param[2], param[4], param[5], param[6], param[7], param[8]
    
    """
    Determine if negative set is to be autogenerated. 
    """
    if '-' in param[0] or gen_neg == 0:
        neg_set = True
    else:
        neg_set = False
    
    '''
    Handlers for input files are initialized, files preprocessed and realigned.
    Alignments are represented by one specialized object each, that handles 
    I/O operations and sequence/set manipulation. 
    See alignment_handler/alignment_handle.py for functions used. 
    '''    
    aln = Alignment_handle(filename, True, function_log)
    aln.remove_all_gaps()
    aln.ident_Filter(maxid, n_proc, mute)
    aln.realign_me()
    '''
    Spawn a set of up to 10 partial alignments per 2..15 sequences. These
    'alignment windows' later form the basis for feature vector calculation.
    Each alignment window is represented by an alignment window object instance
    (see alignment_handler/window_handle.py),
    handling I/O-operations, secondary structure estimation and feature calculations. 
    '''
    aln.spawn_subalignments(minid, maxid, n_proc, window_size, step)
    '''
    Generate control sets for alignment windows. SISSIz is used to simulate
    alignments with identical dinucleotide content and gap patterns. 
    '''
    control_alignments = []
    
    for i in range(0, len(aln.windows)):
        cw = aln.windows[i].generate_control_alignment()
        if verify_file(cw.path) is False:
            function_log.write_log("Failed to generate control alignment for: " + aln.windows[i].identifier + '\n Empty file? \n')
            continue
        control_alignments.append(cw)
        
    '''
    Validation of structural conservation. Tree edit distances to 
    approximate structural distances between sequences are used as
    a metric to estimate overall structural conservation in comparison
    to the control set.
    This way, a sufficient separation between positive and negative 
    training instances on a structural level is ensured. 
    '''
    
    aln_native, aln_negative = k_value_filter(aln.windows, control_alignments, k)
    '''
    Calculate feature vectors and save them in a .dat file. 
    '''
    for i in range(0, len(aln_native)):
        aln_native[i].calculate_feature_vector()
    write_data(aln_native, outfilename)
    
    '''
    If the autogenerated negative set shall be included in the data set - as 
    is usually the case - we have to process that one as well.
    '''
    if gen_neg == 0:
        return 1
        
    for i in range(0, len(aln_negative)):
        aln_negative[i].calculate_feature_vector()
    write_data(aln_negative, outfilename)

    return 1
    
###########################main function call###########################
"""
Main functional procedure - input is a Fasta or clustal alignment file obtained from Rfam, preferably either
regular alignment if |n_seq| < 300, otherwise seed alignment. Other input 
parameters, refer to -h or --man page.
"""

def main(argx=None, inputfile=None, outfile=None, function_log = None):
    THIS_FOLDER = os.path.dirname(os.path.abspath(__file__))
    ret_val = 0
    
    '''
    Should we call for help? 
    '''
    if '-h' in argx or '--man' in argx:
        print_help(THIS_FOLDER)
        return None
    '''
    Handle folder structure, if .ini format input:
    
    (Only a small fraction of use cases, as most will just have a folder of 
    input alignments and autogenerate negative instances from there.)
    '''
    if '/' in inputfile and '.ini' in inputfile:
        in_path = inputfile[:inputfile.rindex('/')+1]
    else:
        in_path = inputfile
    '''
    Initialize base parameters if not happened already (only if using deprecated
    direct function call):
    '''
    if argx == None:
        argx = sys.argv
    else:
        pass
    '''
    Init statlog:
        --Disabled right now, as it is currently more of a debugging tool and 
        for drawing structural conservatuion plots. Might be included for an
        automated pdf report some day...
    '''
    #statlog = creation_statlog(inputfile.split('/')[-1])    
    '''
    Parse arguments with currysoup module:
    '''
    parameters, calls = creation_soup(argx, inputfile, outfile, function_log)
    """
    On main function call, at first input parameters are parsed. Obviously.
    If parameters are not set manually, default values are loaded.
    """

    for i in range(0, len(parameters)):
        if parameters[i] == None:
            parameters[i] = defaults[i]
    if outfile == None:
        if '.fasta' in str(inputfile):
            outfile = inputfile.replace('.fasta', '') + '.dat'
    
    """
    Should negative sets be auto-generated for all instances? 
    """
    auto_gen = parameters[3]
    if auto_gen is None:
        auto_gen = True
    
    """
    If any specific function calls to steps in the pipeline are made, 
    the necessary functions are called now:
    """
    if parameters[7] == False:
        print('Initialization complete. Starting main program...')
    """
    Core function is called with set options:
    """
    if '-readall' in calls:
        '''
        Check if input is .ini file in proper directory - alternative way to input positive and negative sets:
        '''
        if '.ini' in str(inputfile):
        
            try:
                cc = 0
                with open(inputfile) as  inf:
                    for line in inf.readlines():
                        if '#' in line:
                            break
                        else:
                            cc += 1
                            lin_block = line.split(':')
                            if '-' in lin_block[0]:
                                parameters[0] = '-1'
                                if parameters[7] == False:
                                    print('Reading File: ' + str(in_path + str(lin_block[1]).replace('\n', '')))
                                ret_val = create_training_set(in_path + str(lin_block[1]).replace('\n', ''), parameters, outfile, 0, function_log)
                            else:
                                parameters[0] = '1'
                                if parameters[7] == False:
                                    print('Reading File: ' + str(in_path + str(lin_block[1]).replace('\n', '')))
                                ret_val = create_training_set(in_path + str(lin_block[1]).replace('\n', ''), parameters, outfile, 0, function_log)
                    if parameters[7] == False:
                        print("End of input file reached. Data sets observed: " + str(cc))
                    if ret_val == 1:
                        if parameters[7] == False:
                            print("Process complete. Output written to " + str(outfile))
                        return True
                    else:
                        lg_message = "Something went wrong. Please check input format. Since this is an unspecified error, please inform developer."
                        function_log.write_warning(lg_message) 
                        raise ValueError(lg_message)
            except Exception as e:
                function_log.write_log(str(e))
                raise e
        elif os.path.isdir(in_path):
            worktree = []
            '''
            If -readall is called and no .ini file is given, we will traverse target 
            folder structure looking for valid alignments:
            Build a list of alignment files with categories and traverse it:
            '''
            for entry in os.listdir(in_path):
                #category, file_list = read_input_dir(os.path.join(in_path, entry)) 
                #worktree.append((category, file_list))
                if parameters[7] is False:
                    print("Found file: " + str(entry))
                worktree.append(os.path.join(in_path, entry))
            print('End of directory reached. Data sets found: ' + str(len(worktree)))
            
            for f in worktree:
                if auto_gen is True:
                    create_training_set(f, parameters, outfile, 1, function_log)
                else:
                    create_training_set(f, parameters, outfile, 0, function_log)
            ret_val = 1
            
        else:
            lg_message = "FATAL: Input is neither valid fasta file,  .ini file or directory."
            e = TypeError(lg_message)
            function_log.write_log(lg_message)
            raise e
    
    elif '-extract' in calls:
        '''
        The -extract call is disabled for now, as there is no use for it currently.
        Might be removed because of redundancy.
        '''
        pass
        #tripel = extract_data(inputfile)
        #print(parameters[0]+' 1:'+str(tripel[0])+' 2:'+str(tripel[1])+' 3:'+str(tripel[2]))
        #return True
    
    else:
        if auto_gen is False:
            create_training_set(inputfile, parameters, outfile, 0, function_log)
            ret_val = 1
        else:
            create_training_set(inputfile, parameters, outfile, 1, function_log)
            ret_val = 1
    '''
    The return value of create_training_set function specifies if an output
    file could be successfully written:
    '''
    if ret_val == 1:
        '''
        try:
            #statlog.draw_deletion_plot()
            #statlog.draw_distance_plot()
        except Exception:
            lg_message = "Could not write statistic log for graphic distance plot. Skipping..."
            function_log.write_warning(lg_message)
            print(lg_message)
        ''' 
        function_log.write_log("Process exited normally. \n")
        return None
    else:
        lg_message = "Something went wrong. Please check input format. Since this is an unspecified error, please inform developer."
        function_log.write_warning(lg_message) 
        raise ValueError(lg_message)
        
################################# Misc. ################################

def print_help(this_folder):
    with open(os.path.join(this_folder, 'help/generate_data.help'), 'r') as f:
        print(f.read())
    return None

def read_input_dir(dir_entry):
    seq_file_paths = []
    '''    
    If no category is given, ignore these folders:    
    '''    
    if os.path.isdir(dir_entry) and ('_neg_' in str(dir_entry) or '_pos_' in str(dir_entry)):
        for obj in os.listdir(dir_entry):
            if not os.path.isdir(os.path.join(dir_entry, obj)):
                seq_file_paths.append(os.path.abspath(os.path.join(dir_entry, obj)))
        '''
        Check if directory was empty:        
        '''    
        if len(seq_file_paths) == 0:
            return (None, None)
            '''
            Otherwise return filepaths of alignments and respective category:
            '''
        elif '_neg_' in str(dir_entry):
            return '-1',seq_file_paths
        elif '_pos_' in str(dir_entry):
            return '1',seq_file_paths
        '''
        Misc. error case/ should never be reached:
        '''
        raise IOError('Invalid folder - no category could be assigned.')
    else:
        return (None, None)
    
############################Outfile generation #########################
"""
Fills a .dat file with all generated feature vectors
after duplicates are erased (as these are not useful
and only slow down training). This file can be used 
for classifier training.
If -auto flag is set, it will be passed to classifier training automatically.

Numpy array is used to speed up processing, as duplicate filter needs
~40 000 comparison operations in worst case.
"""

def filter_duplicates(vector_array):
    indices = []
    
    for i in range(0, len(vector_array) -1):
        for a in range(i + 1, len(vector_array)):
            if np.array_equal( vector_array[i], vector_array[a]):
                indices.append(i)
                break
            
    return np.delete(vector_array, indices, 0)
    

def write_data(windows, outfilename):
    
    if not outfilename.endswith('.dat'):
        outfilename = outfilename + '.dat'
    vector_array = []
    for i in range(0, len(windows)):
        if windows[i].is_valid():
            vector_array.append([windows[i].get_category()] + windows[i].get_vector())
                
    vector_array = np.asarray(vector_array)
    vector_array = filter_duplicates(vector_array)
    
    with open(outfilename, 'a') as dat:
        for i in range(0, len(vector_array)):
            dat.write(str(vector_array[i][0]) 
            +' 1:'+str(vector_array[i][1])
            +' 2:'+str(vector_array[i][2])
            +' 3:'+str(vector_array[i][3])+'\n')
            
    return 1 

############################Pandas data structure interface ################

def as_data_frame(vector_array):
    
    '''
    Takes an array of feature vectors and gives us a nice Pandas data frame.
    ...Currently not used except for testing/plotting.
    '''
    vector_array_T = np.transpose(vector_array)
    vector_dict = {
            'category' : vector_array_T[0],
            'SCI' : vector_array_T[1],
            'z-Score' : vector_array_T[2],
            'Shannon-Entropy' : vector_array_T[3]
            }
    
    feature_df = DataFrame(data = vector_dict)
    return feature_df

def as_series(vector_array):
    '''
    Takes an array of feature vectors and turns them into series. Simple.
    ...Currently not used except for testing/plotting.
    '''
    vector_array_T = np.transpose(vector_array)
    category_series = Series(data = vector_array_T[0])
    sci_series = Series(data = vector_array_T[1])
    z_series = Series(data = vector_array_T[2])
    entropy_series = Series(data = vector_array_T[3])
    
    return category_series, sci_series, z_series, entropy_series

############################File verification###############################
"""
A helper function that checks if a file is empty. SISSIz mucks up sometimes.
"""

def verify_file(filename):
    if os.path.getsize(filename) == 0:
        lg_message = "WARNING: Could not create valid randomized alignment (empty file). Skipping, but rfam alignment should be rechecked."
        print(lg_message)
        #function_log.write_warning(lg_message)
        return False
    else:
        return True

########################################################################

#NOTE: Sorting is hierarchical from the top down i.e. first sequence is compared to all others, then second......
if __name__ == '__main__':
    main()
    
def testset_cr(argx = None, inputfile=None, outfile=None, flog=None, t=None):
    
    #global function_log
    function_log = flog
    main(argx, inputfile, outfile, function_log)
    return 1
